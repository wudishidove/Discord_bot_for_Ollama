import json
import discord
from discord.ext import commands
import requests
from langchain.memory import ConversationBufferMemory
import time
import asyncio
import os
import base64
from PIL import Image
from io import BytesIO
import re
# å°å…¥ PDF è½‰æ›å‡½æ•¸
from to_html import convert_pdf_to_html
import pymupdf4llm
import pymupdf.pro

# æ¨¡å‹å°æ‡‰çš„æœ€å¤§ token é™åˆ¶
MODEL_MAX_TOKENS = {
    "gemma2:latest": 8192,
    "phi4:latest": 8192,
    "Qwen2.5:7b": 4096,
    "mistral:latest": 8192,
    "llama3.2:latest": 131072,
    "llama3.2-vision:latest": 131072,
    "deepseek-r1:1.5b": 131072,
    "deepseek-r1:latest": 131072,
    "deepseek-r1:8b": 131072,
    "deepseek-r1:14b": 131072,
    "gemma3:12b": 131072,
    "gemma3:27b": 131072,
    "gemma3:nsfw2": 131072,
    "deepseek-r1:32b": 131072
}

# åˆå§‹åŒ–è¨˜æ†¶åŠŸèƒ½ï¼ˆè‡¨æ™‚ä½¿ç”¨ï¼Œæ¯æ¬¡å°è©±å‰éƒ½æœƒé‡æ–°åŠ è¼‰é »é“ç‰¹å®šçš„è¨˜æ†¶ï¼‰
memory = ConversationBufferMemory(
    memory_key="history",
    return_messages=False,
    max_len=128000)  # é»˜èªç‚º phi4 çš„æœ€å¤§ token é™åˆ¶
# ç´€éŒ„ä¸‹è¼‰çš„æª”æ¡ˆå…§å®¹
file_contents = []
# è¼‰å…¥é…ç½®æ–‡ä»¶
with open("config.json", "r") as config_file:
    config = json.load(config_file)

# Discord Bot Token
DISCORD_TOKEN = config["DISCORD_TOKEN"]
# Ollama API URL
OLLAMA_API_URL = "http://localhost:11434/api/generate"

# æŒ‡å®šä¸Šç·šè¨Šæ¯çš„é »é“ ID
STATUS_CHANNEL_ID = 1073495605286027267  # æ›¿æ›ç‚ºä½ çš„é »é“ ID
ALLOWED_CHANNEL_IDS = config["ALLOWED_CHANNEL_IDS"]

# åˆå§‹åŒ– Bot
intents = discord.Intents.default()
intents.messages = True  # å•Ÿç”¨è¨Šæ¯äº‹ä»¶
intents.message_content = True  # å•Ÿç”¨è¨Šæ¯å…§å®¹è¨ªå•
bot = commands.Bot(command_prefix="++", intents=intents)

# å„²å­˜ç•¶å‰é¸æ“‡çš„æ¨¡å‹
current_model = "gemma3:27b"  # é è¨­æ¨¡å‹


def is_in_allowed_channel(ctx):
    return ctx.channel.id in ALLOWED_CHANNEL_IDS


def update_memory_limit():
    """æ ¹æ“šç•¶å‰æ¨¡å‹æ›´æ–°è¨˜æ†¶æœ€å¤§ token é™åˆ¶ï¼ˆåªæ›´æ–°è¨˜æ†¶å¤§å°ï¼Œä¸å½±éŸ¿å…§å®¹ï¼‰"""
    global memory
    max_tokens = MODEL_MAX_TOKENS.get(current_model, 8192)  # é»˜èªç‚º 8192
    # åªæ›´æ–° token é™åˆ¶ï¼Œä¸æœƒæ¸…é™¤ä»»ä½•è¨˜æ†¶å…§å®¹
    memory = ConversationBufferMemory(
        memory_key="history",
        return_messages=False,
        max_len=max_tokens)
    print(f"[DEBUG] è¨˜æ†¶æœ€å¤§ token é™åˆ¶æ›´æ–°ç‚º: {max_tokens}")


def save_history_to_file(channel_id):
    """å°‡è¨˜æ†¶æ­·å²ä¿å­˜åˆ°é »é“ç‰¹å®šçš„ JSON æ–‡ä»¶ä¸­"""
    if not channel_id:
        print("[WARNING] æœªæä¾›é »é“ IDï¼Œç„¡æ³•ä¿å­˜è¨˜æ†¶")
        return
        
    context = memory.load_memory_variables({})
    # ç¢ºä¿é »é“ç›®éŒ„å­˜åœ¨
    os.makedirs(str(channel_id), exist_ok=True)
    history_file_path = os.path.join(str(channel_id), "history.json")
    with open(history_file_path, "w", encoding="utf-8") as history_file:
        json.dump(context, history_file, ensure_ascii=False, indent=4)
    print(f"[DEBUG] é »é“ {channel_id} çš„è¨˜æ†¶å·²ä¿å­˜åˆ° {history_file_path}")


def load_history_from_file(channel_id):
    """å¾é »é“ç‰¹å®šçš„ JSON æ–‡ä»¶ä¸­è¼‰å…¥è¨˜æ†¶æ­·å²"""
    global memory
    
    # é‡ç½®è¨˜æ†¶ï¼ˆç¢ºä¿ä¸æœƒæ··åˆä¸åŒé »é“çš„è¨˜æ†¶ï¼‰
    memory = ConversationBufferMemory(max_token_limit=MODEL_MAX_TOKENS.get(current_model, 8192))
    
    if not channel_id:
        print("[WARNING] æœªæä¾›é »é“ IDï¼Œç„¡æ³•è¼‰å…¥è¨˜æ†¶")
        return False
        
    # è¼‰å…¥æŒ‡å®šé »é“çš„æ­·å²è¨˜æ†¶
    history_file_path = os.path.join(str(channel_id), "history.json")
    if os.path.exists(history_file_path):
        try:
            with open(history_file_path, "r", encoding="utf-8") as history_file:
                context = json.load(history_file)
                if "history" in context:
                    # å°‡æ­·å²åŠ è¼‰åˆ°è¨˜æ†¶ä¸­
                    memory.save_context({"input": ""}, {"output": context["history"]})
                    print(f"[DEBUG] å·²è¼‰å…¥é »é“ {channel_id} çš„è¨˜æ†¶æ­·å²")
                    return True
        except Exception as e:
            print(f"[ERROR] è¼‰å…¥é »é“ {channel_id} çš„è¨˜æ†¶æ­·å²æ™‚å‡ºéŒ¯: {e}")
    else:
        print(f"[DEBUG] é »é“ {channel_id} æ²’æœ‰æ­·å²è¨˜æ†¶æ–‡ä»¶ï¼Œä½¿ç”¨ç©ºè¨˜æ†¶")
    
    return False


def trim_memory_with_ollama(channel_id):
    """ä½¿ç”¨ Ollama æ¨¡å‹è£å‰ªè¨˜æ†¶æ­·å²"""
    if not channel_id:
        print("[WARNING] æœªæä¾›é »é“ IDï¼Œç„¡æ³•è£å‰ªè¨˜æ†¶")
        return
        
    context = memory.load_memory_variables({})
    history = context.get("history", "")
    estimated_tokens = len(history.split())  # ç°¡å–®ä¼°ç®—tokenæ•¸
    
    # å¦‚æœtokenæ•¸å°æ–¼æœ€å¤§é™åˆ¶çš„50%ï¼Œä¸éœ€è£æ¸›
    if estimated_tokens < MODEL_MAX_TOKENS[current_model] * 0.5:
        print(f"[DEBUG] ç•¶å‰tokenæ•¸ï¼ˆç´„{estimated_tokens}ï¼‰ä¸éœ€è£æ¸›")
        return

    # ç™¼é€è«‹æ±‚åˆ° Ollama æ¨¡å‹
    trim_prompt = """è«‹åˆ†æä»¥ä¸‹å°è©±æ­·å²ï¼Œä¸¦é€²è¡Œé‡è¦å…§å®¹æå–ï¼š
    1. ä¿ç•™é—œéµçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    2. ä¿æŒå°è©±çš„é€£è²«æ€§
    3. å„ªå…ˆä¿ç•™æœ€è¿‘çš„å°è©±
    4. åˆªé™¤é‡è¤‡æˆ–ä¸é‡è¦çš„å…§å®¹
    
    å°è©±æ­·å²ï¼š
    {history}
    
    è«‹æä¾›ç²¾ç°¡å¾Œçš„é‡è¦å°è©±ï¼š""".format(history=history)

    response = requests.post(
        OLLAMA_API_URL,
        json={"model": current_model, "prompt": trim_prompt},
        headers={"Content-Type": "application/json"}
    )

    if response.status_code == 200:
        try:
            result = response.json()
            trimmed_history = result.get("response", "")
            print("[DEBUG] è£å‰ªå¾Œçš„è¨˜æ†¶æ­·å²ï¼š", trimmed_history)
            print(f"[DEBUG] è£å‰ªå‰tokenæ•¸ï¼š{estimated_tokens}ï¼Œè£å‰ªå¾Œtokenæ•¸ï¼š{len(trimmed_history.split())}")

            # æ›´æ–°è¨˜æ†¶
            memory.save_context({"input": ""}, {"output": trimmed_history})
            save_history_to_file(channel_id)  # ä¿å­˜è£å‰ªå¾Œçš„è¨˜æ†¶
        except json.JSONDecodeError as e:
            print("[ERROR] ç„¡æ³•è§£æè£å‰ªå›æ‡‰ï¼š", e)
    else:
        print("[ERROR] Ollama API è¿”å›éŒ¯èª¤ï¼š", response.status_code, response.text)


def process_user_input(user_input, channel_id):
    """è™•ç†ç”¨æˆ¶è¼¸å…¥ï¼Œä½¿ç”¨ Ollama API ä¸¦å„²å­˜è¨˜æ†¶"""
    try:
        # å…ˆåŠ è¼‰é »é“ç‰¹å®šçš„è¨˜æ†¶
        load_history_from_file(channel_id)
        
        # æª¢æŸ¥ä¸¦å¯èƒ½è£æ¸›è¨˜æ†¶
        context = memory.load_memory_variables({})
        current_tokens = len(context.get("history", "").split())  # ç°¡å–®ä¼°ç®—tokenæ•¸
        
        # å¦‚æœè¶…éæœ€å¤§é™åˆ¶çš„80%ï¼Œè§¸ç™¼è£æ¸›
        if current_tokens > MODEL_MAX_TOKENS[current_model] * 0.8:
            print(f"[DEBUG] ç•¶å‰tokenæ•¸ï¼ˆç´„{current_tokens}ï¼‰è¶…éé™åˆ¶çš„80%ï¼Œè§¸ç™¼è£æ¸›")
            trim_memory_with_ollama(channel_id)
            # é‡æ–°è¼‰å…¥è£æ¸›å¾Œçš„ä¸Šä¸‹æ–‡
            context = memory.load_memory_variables({})

        prompt_with_memory = context.get("history", "") + f"\nUser: {user_input}\nBot:"

        print("[DEBUG] Prompt sent to Ollama API:", prompt_with_memory)
        start_time = time.time()
        full_prompt = f"å¦‚æˆ‘ç”¨ç¹é«”ä¸­æ–‡å•å•é¡Œï¼Œä¹Ÿè«‹ä½ ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦ä¸ä½¿ç”¨ä»»ä½•ç‰¹æ®Šå­—ç¬¦å’Œè¡¨æƒ…ï¼š{prompt_with_memory}"
        prompt_with_memory = full_prompt
        # ç™¼é€åˆ° Ollama API
        response = requests.post(
            OLLAMA_API_URL,
            json={"model": current_model, "prompt": prompt_with_memory},
            headers={"Content-Type": "application/json"}
        )

        if response.status_code == 200:
            try:
                # è¨ˆç®—è™•ç†æ™‚é–“
                elapsed_time = time.time() - start_time
                # æª¢æŸ¥æ˜¯å¦ç‚ºé€è¡Œ JSON å›æ‡‰
                if '\n' in response.text:
                    full_response = ""
                    for line in response.text.splitlines():
                        try:
                            data = json.loads(line)
                            full_response += data.get("response", "")
                            if data.get("done", False):
                                break
                        except json.JSONDecodeError:
                            continue
                    memory.save_context({"input": user_input}, {
                                        "output": full_response})
                    print("[DEBUG] Full response processed:", full_response)
                    save_history_to_file(channel_id)  # ä¿å­˜è¨˜æ†¶æ­·å²
                    return full_response.strip(), elapsed_time
                else:
                    # å–®è¡Œ JSON å›æ‡‰
                    result = response.json()
                    bot_response = result.get("response", "æ¨¡å‹æœªè¿”å›å…§å®¹ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
                    # æ›´æ–°è¨˜æ†¶
                    memory.save_context({"input": user_input}, {
                                        "output": bot_response})
                    print("[DEBUG] Single-line response:", bot_response)
                    save_history_to_file(channel_id)  # ä¿å­˜è¨˜æ†¶æ­·å²
                    return bot_response, elapsed_time
            except json.JSONDecodeError as e:
                raise Exception(f"JSON è§£ç¢¼éŒ¯èª¤ï¼š{e}")
        else:
            raise Exception(
                f"Ollama API Error: {response.status_code} - {response.text}"
            )
    except Exception as e:
        raise Exception(f"è™•ç†è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

def handle_file_upload(filepath):
    """è™•ç†æ–‡ä»¶ä¸Šå‚³ï¼Œä¸¦è¿”å›æ–‡ä»¶å…§å®¹"""
    try:
        ext = os.path.splitext(filepath)[1].lower()
        # ä½¿ç”¨çµ•å°è·¯å¾‘ä¾†ç²å–é »é“ ID å’Œæ–‡ä»¶ç›®éŒ„
        abs_filepath = os.path.abspath(filepath)
        channel_dir = os.path.dirname(abs_filepath) # ç²å–é »é“ç›®éŒ„çš„çµ•å°è·¯å¾‘
        channel_id = os.path.basename(channel_dir) # å‡è¨­é »é“ç›®éŒ„åç¨±å°±æ˜¯é »é“ ID
        
        print(f"[DEBUG] è™•ç†æ–‡ä»¶ (çµ•å°è·¯å¾‘): {abs_filepath}")
        print(f"[DEBUG] æ–‡ä»¶é¡å‹: {ext}")
        print(f"[DEBUG] é »é“ç›®éŒ„ (çµ•å°è·¯å¾‘): {channel_dir}")
        print(f"[DEBUG] é »é“ ID: {channel_id}")
        
        # è®€å–æˆ–åˆå§‹åŒ–é »é“çš„æ–‡ä»¶å…§å®¹ (ä½¿ç”¨çµ•å°è·¯å¾‘)
        file_contents_path = os.path.join(channel_dir, 'file_contents.json')
        
        try:
            if os.path.exists(file_contents_path):
                print(f"[DEBUG] ç™¼ç¾ç¾æœ‰çš„ file_contents.json")
                with open(file_contents_path, 'r', encoding='utf-8') as f:
                    channel_file_contents = json.load(f)
            else:
                print(f"[DEBUG] æœªæ‰¾åˆ° file_contents.jsonï¼Œå°‡å‰µå»ºæ–°çš„")
                channel_file_contents = []
        except Exception as e:
            print(f"[ERROR] è®€å–æ–‡ä»¶å…§å®¹åˆ—è¡¨æ™‚å‡ºéŒ¯: {e}")
            channel_file_contents = []
        
        # è™•ç†åœ–ç‰‡æª”æ¡ˆ
        if ext in ('.png', '.jpg', '.jpeg', '.gif', '.bmp'):
            try:
                img_content = image_to_base64(abs_filepath) # ä½¿ç”¨çµ•å°è·¯å¾‘
                if img_content:
                    # ä¿å­˜ base64 åœ–ç‰‡åˆ—è¡¨åˆ°é »é“è³‡æ–™å¤¾ (ä½¿ç”¨çµ•å°è·¯å¾‘)
                    base64_file_path = os.path.join(channel_dir, 'image_base64_list.json')
                    try:
                        # è®€å–ç¾æœ‰çš„ base64 åˆ—è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if os.path.exists(base64_file_path):
                            with open(base64_file_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                existing_data = data.get('images', [])
                                idle_count = data.get('idle_count', 0)
                        else:
                            existing_data = []
                            idle_count = 0
                        
                        # é‡ç½® idle count å› ç‚ºæœ‰æ–°åœ–ç‰‡
                        idle_count = 0
                        
                        # æ·»åŠ æ–°çš„ base64 åœ–ç‰‡
                        image_data = {
                            'filename': os.path.basename(abs_filepath),
                            'base64_content': img_content,
                            'timestamp': time.time()
                        }
                        existing_data.append(image_data)
                        
                        # ä¿å­˜æ›´æ–°å¾Œçš„åˆ—è¡¨å’Œ idle count
                        with open(base64_file_path, 'w', encoding='utf-8') as f:
                            json.dump({
                                'images': existing_data,
                                'idle_count': idle_count
                            }, f, ensure_ascii=False, indent=4)
                        
                        print(f"[DEBUG] å·²ä¿å­˜ base64 åœ–ç‰‡åˆ°: {base64_file_path}")
                    except Exception as e:
                        print(f"[ERROR] ä¿å­˜ base64 åœ–ç‰‡åˆ—è¡¨æ™‚å‡ºéŒ¯: {e}")
                    
                    return True
            except Exception as e:
                print(f"[ERROR] åœ–ç‰‡è™•ç†éŒ¯èª¤: {e}")
                return False
        
        # è™•ç†æ–‡å­—æª”æ¡ˆ
        else:
            file_content = read_file_content(abs_filepath) # ä½¿ç”¨çµ•å°è·¯å¾‘
            print(f"[DEBUG] è®€å–åˆ°çš„æ–‡ä»¶å…§å®¹: {file_content[:200]}...")  # åªæ‰“å°å‰200å€‹å­—ç¬¦
            
            if file_content != "[Unsupported file type]":
                # æ·»åŠ æ–°çš„æ–‡ä»¶å…§å®¹
                # ä½¿ç”¨çµ•å°è·¯å¾‘è¨˜éŒ„æª”æ¡ˆåç¨±
                new_content = f"æª”æ¡ˆåç¨±: {abs_filepath}\næª”æ¡ˆå…§å®¹: {file_content}"
                channel_file_contents.append(new_content)
                
                # ä¿å­˜æ›´æ–°å¾Œçš„æ–‡ä»¶å…§å®¹åˆ—è¡¨
                try:
                    with open(file_contents_path, 'w', encoding='utf-8') as f:
                        json.dump(channel_file_contents, f, ensure_ascii=False, indent=4)
                    print(f"[DEBUG] æˆåŠŸå¯«å…¥ file_contents.json")
                except Exception as e:
                    print(f"[ERROR] å¯«å…¥ file_contents.json æ™‚å‡ºéŒ¯: {e}")
                    return False
                return True
            else:
                print(f"[WARNING] ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {filepath}")
                return False
                
    except Exception as e:
        print(f"[ERROR] æª”æ¡ˆè™•ç†éŒ¯èª¤: {e}")
        return False

def image_idle_check(channel_id):
    """æª¢æŸ¥ä¸¦ç®¡ç†åœ–ç‰‡å¿«å–
    - æ¯æ¬¡è¢«æåŠæ™‚å¢åŠ é–’ç½®è¨ˆæ•¸
    - ç•¶åœ–ç‰‡è¶…éæœ€å¤§æ•¸é‡æˆ–é–’ç½®æ¬¡æ•¸éå¤šæ™‚æ¸…ç†
    - æ¸…ç†æ™‚å„ªå…ˆæ¸…ç†æœ€èˆŠçš„åœ–ç‰‡
    """
    # è¨­å®šæœ€å¤§åœ–ç‰‡æ•¸é‡å’Œæœ€å¤§é–’ç½®æ¬¡æ•¸
    MAX_IMAGES = 10
    MAX_IDLE_COUNT = 20
    
    try:
        base64_file_path = os.path.join(str(channel_id), 'image_base64_list.json')
        if os.path.exists(base64_file_path):
            with open(base64_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                image_data_list = data.get('images', [])
                idle_count = data.get('idle_count', 0)
            
            # å¢åŠ é–’ç½®è¨ˆæ•¸
            idle_count += 1
            
            # æª¢æŸ¥é–’ç½®æ¬¡æ•¸
            if idle_count > MAX_IDLE_COUNT and image_data_list:
                # ç§»é™¤æœ€èˆŠçš„åœ–ç‰‡
                image_data_list.pop(0)
                print("[DEBUG] å¤ªä¹…æ²’ç”¨ï¼Œå·²ç§»é™¤æœ€èˆŠçš„åœ–ç‰‡")
                print(f"[DEBUG] ç•¶å‰å¿«å–åœ–ç‰‡æ•¸é‡: {len(image_data_list)}, é–’ç½®æ¬¡æ•¸: {idle_count}")
            
            # æª¢æŸ¥åœ–ç‰‡æ•¸é‡æ˜¯å¦è¶…éé™åˆ¶
            while len(image_data_list) > MAX_IMAGES:
                image_data_list.pop(0)  # ç§»é™¤æœ€èˆŠçš„åœ–ç‰‡
                print("[DEBUG] åœ–ç‰‡æ•¸é‡è¶…éé™åˆ¶ï¼Œå·²ç§»é™¤æœ€èˆŠçš„åœ–ç‰‡")
            
            # ä¿å­˜æ›´æ–°å¾Œçš„åˆ—è¡¨å’Œ idle count
            with open(base64_file_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'images': image_data_list,
                    'idle_count': idle_count
                }, f, ensure_ascii=False, indent=4)
            
    except Exception as e:
        print(f"[ERROR] åœ–ç‰‡å¿«å–ç®¡ç†éŒ¯èª¤: {e}")
        # ç™¼ç”ŸéŒ¯èª¤æ™‚é‡ç½®ç‹€æ…‹
        if os.path.exists(base64_file_path):
            with open(base64_file_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'images': [],
                    'idle_count': 0
                }, f)


def image_to_base64(image_path):
    """å°‡åœ–ç‰‡è½‰æ›ç‚º base64 ç·¨ç¢¼"""
    try:
        with Image.open(image_path) as img:
            buffered = BytesIO()
            # ç¢ºå®šåœ–ç‰‡çš„æ ¼å¼
            image_format = img.format.lower() if img.format else 'png'
            
            # æ ¹æ“šåœ–ç‰‡æ ¼å¼é¸æ“‡ä¿å­˜æ ¼å¼
            save_format = {
                'jpeg': 'JPEG',
                'jpg': 'JPEG',
                'gif': 'GIF',
                'bmp': 'BMP',
                'tiff': 'TIFF',
                'png': 'PNG'
            }.get(image_format, 'PNG')
            
            img.save(buffered, format=save_format)
            return base64.b64encode(buffered.getvalue()).decode('utf-8')
    except Exception as e:
        print(f"[ERROR] åœ–ç‰‡è½‰æ›éŒ¯èª¤ {image_path}: {e}")
        return None
def read_pdf_content(filepath):
    # è®“ to_markdown() å›å‚³æ¯ä¸€é çš„çµæ§‹åŒ–è³‡æ–™ï¼Œä¸¦æå–åœ–ç‰‡
    chunks = pymupdf4llm.to_markdown(
        doc= filepath,
        write_images=True,
        image_format='jpg',
        image_path="images",
        page_chunks=True
    )

    # å–å¾—æ‰€æœ‰é é¢ä¸­åœ–ç‰‡çš„æª”æ¡ˆåç¨±
    pdf_text=''
    image_filenames = []
    for page in chunks:
        pdf_text += f'page {page["metadata"]["page"]}:\n'
        pdf_text += f'{page["text"]}'
    # åˆ©ç”¨æ­£å‰‡è¡¨é”å¼æŠ“å–æ‰€æœ‰ç¬¦åˆ Markdown åœ–ç‰‡èªæ³•çš„éƒ¨åˆ†
    image_filenames = re.findall(r'!\[\]\((images/[^)]+\.jpg)\)', pdf_text)

    return pdf_text, image_filenames

def read_file_content(filepath):
    """è®€å–æ–‡ä»¶å…§å®¹"""
    ext = os.path.splitext(filepath)[1].lower()
    
    try:
        if ext == '.txt':
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
                return content if content.strip() else "[Empty file]"
        elif ext == '.pdf':
            # ç¢ºä¿ PDF æ–‡ä»¶è·¯å¾‘æ˜¯çµ•å°è·¯å¾‘
            pdf_filepath = os.path.abspath(filepath)
            
            # PDF to markdownåŸºç¤è½‰æ›
            # md_text = pymupdf4llm.to_markdown(pdf_filepath)
            md_text, image_filenames = read_pdf_content(pdf_filepath)
            return md_text if md_text.strip() else "[Empty file]"

            # # ç²å– PDF æ–‡ä»¶æ‰€åœ¨çš„é »é“ç›®éŒ„
            # channel_dir = os.path.dirname(pdf_filepath)
            
            # # è¨­å®šè¼¸å‡ºçš„ HTML æ–‡ä»¶çš„çµ•å°è·¯å¾‘
            # html_filename = os.path.splitext(os.path.basename(pdf_filepath))[0] + '.html'
            # html_filepath = os.path.abspath(os.path.join(channel_dir, html_filename))
            
            # print("debug, pdf_filepath:", pdf_filepath)
            # print("debug, html_filepath:", html_filepath)
            
            # # è½‰æ› PDF åˆ° HTML
            # if convert_pdf_to_html(pdf_filepath, html_filepath):
            #     # å¦‚æœè½‰æ›æˆåŠŸ,è®€å– HTML å…§å®¹
            #     try:
            #         with open(html_filepath, 'r', encoding='utf-8') as f:
            #             content = f.read()
            #         # åˆªé™¤ç”Ÿæˆçš„ HTML æ–‡ä»¶
            #         # try:
            #         #     os.remove(html_filepath)
            #         # except:
            #         #     pass
            #         return content
            #     except Exception as e:
            #         return f"[Error reading converted HTML file: {str(e)}]"
            # else:
            #     return "[PDF conversion failed]"
        else:
            return "[Unsupported file type]"
    except UnicodeDecodeError:
        return "[File encoding error]"
    except Exception as e:
        print(f"[ERROR] æª”æ¡ˆè®€å–éŒ¯èª¤ {filepath}: {e}")
        return f"[Error reading file: {str(e)}]"

@bot.event
async def on_ready():
    """ç•¶ Bot ä¸Šç·šæ™‚è§¸ç™¼"""
    print("Bot å·²æˆåŠŸå•Ÿå‹•ï¼")
    print(f"å·²ç™»å…¥ Discord å¸³æˆ¶ï¼š{bot.user}")

    # ç™¼é€ä¸Šç·šé€šçŸ¥åˆ°æ‰€æœ‰å…è¨±çš„é »é“
    for channel_id in ALLOWED_CHANNEL_IDS:
        channel = bot.get_channel(channel_id)
        if channel:
            try:
                await channel.send("ğŸ¤– Bot å·²ä¸Šç·šï¼Œæº–å‚™æ¥æ”¶æŒ‡ä»¤ï¼")
            except Exception as e:
                print(f"ç™¼é€ä¸Šç·šé€šçŸ¥åˆ°é »é“ {channel_id} æ™‚å‡ºç¾éŒ¯èª¤ï¼š{e}")
        else:
            print(f"ç„¡æ³•æ‰¾åˆ°é »é“ IDï¼š{channel_id}")

bot.remove_command("help")


@bot.command()
@commands.check(is_in_allowed_channel)
async def help(ctx):
    """é¡¯ç¤ºå¯ç”¨æŒ‡ä»¤æ¸…å–®"""
    help_message = """
ğŸ¤– **å¯ç”¨æŒ‡ä»¤æ¸…å–®**:
1. **++chat <è¨Šæ¯>** - èˆ‡ Bot é€²è¡Œå°è©±ã€‚
2. **++setmodel <æ¨¡å‹åç¨±>** - é¸æ“‡è¦ä½¿ç”¨çš„æ¨¡å‹ã€‚
3. **++help** - é¡¯ç¤ºæ­¤å¹«åŠ©è¨Šæ¯ã€‚
4. **++clean_history** - æ¸…é™¤ç•¶å‰é »é“çš„è¨˜æ†¶æ­·å²å’Œæª”æ¡ˆã€‚

ğŸ“˜ **å¯ç”¨æ¨¡å‹**:
- é è¨­æ¨¡å‹: gemma3:27b
- gemma3:12b    å¿«é€Ÿå›ç­”ï¼Œä¸€èˆ¬ä½¿ç”¨ï¼Œåœ–ç‰‡ç†è§£å‹‰å¼·
- gemma3:27b    å›ç­”é€Ÿåº¦æ…¢ï¼Œèƒ½åŠ›è¼ƒå¥½ï¼Œåœ–ç‰‡ç†è§£å¼·(è‡ªå¸¶è‹±æ–‡OCR)
- gemma3:nsfw2  NSFWé­”æ”¹ç‰ˆ,æœ‰æ™‚å€™æœƒèƒ¡è¨€äº‚èª
- deepseek-r1:32b é«˜ç­‰è¤‡é›œåº¦ æœƒè¼¸å‡ºæ¨ç†(æ€è€ƒ)éç¨‹
- 
ğŸ¯ **ä½¿ç”¨æ–¹å¼**:
- è¼¸å…¥ `++chat ä½ å¥½` èˆ‡ Bot é–‹å§‹å°è©±ã€‚
- è¼¸å…¥ `++setmodel gemma3:27b` åˆ‡æ›åˆ°æŒ‡å®šçš„æ¨¡å‹ã€‚
- è¼¸å…¥ `++help` æŸ¥çœ‹å¯ç”¨æŒ‡ä»¤æ¸…å–®ã€‚
- è¼¸å…¥ `++clean_history` æ¸…é™¤ç•¶å‰é »é“çš„è¨˜æ†¶æ­·å²å’Œæª”æ¡ˆã€‚
"""
    await ctx.send(help_message)


@commands.check(is_in_allowed_channel)
@bot.command(name="chat")
async def chat(ctx, *, user_input: str):
    """è™•ç†èŠå¤©æŒ‡ä»¤"""
    try:
        print(f"æ”¶åˆ°æŒ‡ä»¤ï¼š{user_input}")
        thinking_message = await ctx.send(f"å·²æ”¶åˆ°ï¼š{user_input}ï¼Œæ­£åœ¨æ€è€ƒ...")

        # ç”Ÿæˆ Ollama å›æ‡‰ï¼Œå‚³å…¥é »é“ ID
        response, _ = process_user_input(user_input, ctx.channel.id)
        response = response.strip()
        await thinking_message.delete()

        if response and response != "æ¨¡å‹æœªè¿”å›å…§å®¹ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚":
            await ctx.send(response)
        else:
            await ctx.send("æ¨¡å‹æœªè¿”å›å…§å®¹æˆ–ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
    except Exception as e:
        print("[ERROR] Exception in chat command:", e)
        await ctx.send(f"å‡ºç¾éŒ¯èª¤ï¼š{e}")


@bot.command()
@commands.check(is_in_allowed_channel)
async def setmodel(ctx, model_name: str):
    """è¨­å®šä½¿ç”¨çš„æ¨¡å‹"""
    global current_model
    available_models = ["gemma3:nsfw2", "gemma3:27b","gemma3:12b","deepseek-r1:32b"]
    if model_name in available_models:
        current_model = model_name
        update_memory_limit()  # æ›´æ–°è¨˜æ†¶é™åˆ¶
        print("[DEBUG] Model switched to:", model_name)
        await ctx.send(f"å·²å°‡æ¨¡å‹åˆ‡æ›ç‚º `{model_name}`ï¼Œè¨˜æ†¶æœ€å¤§é™åˆ¶æ›´æ–°ç‚º {MODEL_MAX_TOKENS[model_name]} tokensã€‚")
    else:
        print("[ERROR] Invalid model name:", model_name)
        await ctx.send(f"ç„¡æ•ˆçš„æ¨¡å‹åç¨±ï¼å¯ç”¨æ¨¡å‹ï¼š{', '.join(available_models)}")


@bot.command()
@commands.check(is_in_allowed_channel)
async def clean_history(ctx):
    """æ¸…é™¤é »é“çš„è¨˜æ†¶æ­·å²å’Œä¸‹è¼‰çš„æª”æ¡ˆ"""
    global memory
    
    # æ¸…é™¤è¨˜æ†¶æ­·å²
    memory = ConversationBufferMemory(
        max_token_limit=MODEL_MAX_TOKENS.get(current_model, 8192))
    print(f"[DEBUG] é »é“ {ctx.channel.id} çš„è¨˜æ†¶æ­·å²å·²æ¸…é™¤")
    
    # æ¸…é™¤æ­·å²è¨˜æ†¶æ–‡ä»¶
    history_file_path = os.path.join(str(ctx.channel.id), "history.json")
    if os.path.exists(history_file_path):
        try:
            os.unlink(history_file_path)
            print(f"[DEBUG] å·²åˆªé™¤è¨˜æ†¶æ­·å²æ–‡ä»¶: {history_file_path}")
        except Exception as e:
            print(f"[ERROR] åˆªé™¤è¨˜æ†¶æ­·å²æ–‡ä»¶æ™‚å‡ºéŒ¯ {history_file_path}: {e}")
    
    # æ¸…é™¤ userFile ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
    try:
        userfile_dir = str(ctx.channel.id)
        if os.path.exists(userfile_dir):
            for filename in os.listdir(userfile_dir):
                file_path = os.path.join(userfile_dir, filename)
                try:
                    if os.path.isfile(file_path):
                        os.unlink(file_path)
                        print(f"[DEBUG] å·²åˆªé™¤æª”æ¡ˆ: {file_path}")
                except Exception as e:
                    print(f"[ERROR] åˆªé™¤æª”æ¡ˆæ™‚å‡ºéŒ¯ {file_path}: {e}")
            print(f"[DEBUG] é »é“ {ctx.channel.id} çš„æª”æ¡ˆç›®éŒ„å·²æ¸…ç©º")
    except Exception as e:
        print(f"[ERROR] æ¸…ç†é »é“ {ctx.channel.id} çš„æª”æ¡ˆç›®éŒ„æ™‚å‡ºéŒ¯: {e}")
    
    await ctx.send(f"é »é“ {ctx.channel.name} çš„è¨˜æ†¶æ­·å²å’Œä¸‹è¼‰çš„æª”æ¡ˆå·²æˆåŠŸæ¸…é™¤ï¼")




async def stream_response(user_input, channel_id):
    """
    ä½¿ç”¨æµå¼è«‹æ±‚å¾ Ollama API å–å¾—éƒ¨åˆ†å›æ‡‰ï¼Œä¸¦æ¯å…©ç§’ yield ç•¶å‰ç´¯ç©å…§å®¹
    """
    # åŠ è¼‰é »é“ç‰¹å®šçš„è¨˜æ†¶
    load_history_from_file(channel_id)
    
    # æ•´åˆä¸Šä¸‹æ–‡è¨˜æ†¶
    context = memory.load_memory_variables({})
    current_tokens = len(context.get("history", "").split())  # ç°¡å–®ä¼°ç®—tokenæ•¸
    
    # å¦‚æœè¶…éæœ€å¤§é™åˆ¶çš„80%ï¼Œè§¸ç™¼è£æ¸›
    if current_tokens > MODEL_MAX_TOKENS[current_model] * 0.8:
        print(f"[DEBUG] ç•¶å‰tokenæ•¸ï¼ˆç´„{current_tokens}ï¼‰è¶…éé™åˆ¶çš„80%ï¼Œè§¸ç™¼è£æ¸›")
        trim_memory_with_ollama(channel_id)
        # é‡æ–°è¼‰å…¥è£æ¸›å¾Œçš„ä¸Šä¸‹æ–‡
        context = memory.load_memory_variables({})

    prompt_with_memory = context.get("history", "") + f"\nUser: {user_input}\nBot:"
    
    
    full_prompt = f"""å¦‚æˆ‘ç”¨ç¹é«”ä¸­æ–‡å•å•é¡Œï¼Œä¹Ÿè«‹ä½ ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¸”è€å¯¦å›ç­”(ä¸çŸ¥é“å°±è€å¯¦èªªä¸çŸ¥é“ï¼Œ
    é™¤éæˆ‘ç‰¹åˆ¥è«‹ä½ å¤©é¦¬è¡Œç©ºç™¼æ®å‰µæ„)ï¼Œä¸¦ä¸ä½¿ç”¨ä»»ä½•ç‰¹æ®Šå­—ç¬¦å’Œè¡¨æƒ…ï¼Œä¸‹é¢é–‹å§‹æ˜¯æˆ‘çš„å•é¡Œã€‚{prompt_with_memory}"""
    print("[DEBUG] Prompt sent to Ollama API:", full_prompt)
    # å¾ JSON æª”æ¡ˆè®€å–åœ–ç‰‡åˆ—è¡¨
    base64_images = []
    base64_file_path = os.path.join(str(channel_id), 'image_base64_list.json')
    if os.path.exists(base64_file_path):
        try:
            with open(base64_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                image_data_list = data.get('images', [])
                base64_images = [item['base64_content'] for item in image_data_list]
                print(f"[DEBUG] å·²å¾ {base64_file_path} è®€å– {len(base64_images)} å¼µåœ–ç‰‡")
        except Exception as e:
            print(f"[ERROR] è®€å–åœ–ç‰‡åˆ—è¡¨æ™‚å‡ºéŒ¯: {e}")
    
    # ä½¿ç”¨ requests çš„ stream æ¨¡å¼ (run_in_executor é¿å…é˜»å¡)
    loop = asyncio.get_event_loop()
    response = await loop.run_in_executor(
        None,
        lambda: requests.post(
            OLLAMA_API_URL,
            json={
                "model": current_model,
                "prompt": full_prompt,
                "images": base64_images,
                "stream": True
            },
            headers={"Content-Type": "application/json"},
        )
    )
    
    buffer = ""
    last_update = time.time()
    
    # é€è¡Œè™•ç†æµå¼å›æ‡‰
    for line in response.iter_lines(decode_unicode=True):
        if line:
            try:
                data = json.loads(line)
                new_text = data.get("response", "")
                buffer += new_text
                # æ¯0.5ç§’ yield ç•¶å‰ç´¯ç©çµæœ
                if time.time() - last_update >= 0.5:
                    yield buffer
                    last_update = time.time()
                if data.get("done", False):
                    break
            except json.JSONDecodeError:
                continue
    yield buffer

@bot.event
async def on_message(message):
    # å¿½ç•¥è‡ªå·±èˆ‡éå…è¨±é »é“è¨Šæ¯
    if message.author == bot.user or message.channel.id not in ALLOWED_CHANNEL_IDS:
        return

    # å‰µå»º userFile ç›®éŒ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(str(message.channel.id), exist_ok=True)
    
    # è™•ç†é™„åŠ æª”æ¡ˆ
    if message.attachments:
        # ç™¼é€åˆå§‹è™•ç†è¨Šæ¯
        processing_msg = await message.channel.send("ğŸ“‚ æ­£åœ¨è™•ç†ä¸Šå‚³çš„æª”æ¡ˆ...")
        
        # ç”¨æ–¼è¨˜éŒ„è™•ç†çµæœçš„åˆ—è¡¨
        processing_results = []
        
        for attachment in message.attachments:
            # è¨­å®šå„²å­˜è·¯å¾‘
            file_path = os.path.join(str(message.channel.id), attachment.filename)
            # ä¸‹è¼‰æª”æ¡ˆ
            await attachment.save(file_path)
            print(f"[DEBUG] å·²ä¸‹è¼‰æª”æ¡ˆ: {file_path}")
            
            # è®€å–æª”æ¡ˆå…§å®¹
            try:
                result = handle_file_upload(file_path)
                if result:
                    ext = os.path.splitext(file_path)[1].lower()
                    if ext in ('.png', '.jpg', '.jpeg', '.gif', '.bmp'):
                        processing_results.append(f"âœ… åœ–ç‰‡ `{attachment.filename}` è™•ç†æˆåŠŸ")
                    else:
                        processing_results.append(f"âœ… æ–‡ä»¶ `{attachment.filename}` è™•ç†æˆåŠŸ")
                else:
                    processing_results.append(f"âŒ æª”æ¡ˆ `{attachment.filename}` è™•ç†å¤±æ•—")
            except Exception as e:
                print(f"[ERROR] è®€å–æª”æ¡ˆéŒ¯èª¤: {e}")
                processing_results.append(f"âŒ æª”æ¡ˆ `{attachment.filename}` è™•ç†å‡ºéŒ¯: {str(e)}")

        # æ›´æ–°è™•ç†è¨Šæ¯ï¼Œé¡¯ç¤ºæ‰€æœ‰æª”æ¡ˆçš„è™•ç†çµæœ
        result_message = "ğŸ“‹ æª”æ¡ˆè™•ç†çµæœï¼š\n" + "\n".join(processing_results)
        await processing_msg.edit(content=result_message)

    # ç•¶è¨Šæ¯æåŠ Bot æ™‚
    if bot.user.mentioned_in(message):
        image_idle_check(message.channel.id)
        user_input = message.content.replace(bot.user.mention, "").strip()
        
        # è®€å–é »é“çš„æ–‡ä»¶å…§å®¹
        file_contents_path = os.path.join(str(message.channel.id), 'file_contents.json')
        channel_file_contents = []
        if os.path.exists(file_contents_path):
            try:
                with open(file_contents_path, 'r', encoding='utf-8') as f:
                    channel_file_contents = json.load(f)
            except Exception as e:
                print(f"[ERROR] è®€å–æ–‡ä»¶å…§å®¹åˆ—è¡¨æ™‚å‡ºéŒ¯: {e}")
        
        # å¦‚æœæœ‰æª”æ¡ˆï¼Œå°‡æª”æ¡ˆå…§å®¹åŠ å…¥åˆ°ç”¨æˆ¶è¼¸å…¥ä¸­
        if channel_file_contents:
            file_content_text = "\n\n".join(channel_file_contents)
            user_input = f"{user_input}\n\nç”¨æˆ¶ä¸Šå‚³çš„æª”æ¡ˆï¼š\n{file_content_text}"
            print(f"[DEBUG] å·²è®€å–æª”æ¡ˆå…§å®¹+ä½¿ç”¨è€…å•é¡Œ: {user_input}")
        
        if not user_input and not channel_file_contents:
            return
        
        # å…ˆç™¼é€ä¸€å‰‡åˆå§‹è¨Šæ¯ï¼Œä¸¦ç”¨ä¸€å€‹åˆ—è¡¨ä¿å­˜æ‰€æœ‰è¨Šæ¯ï¼ˆå¾ŒçºŒä¾åºæ›´æ–°ï¼‰
        thinking_messages = []
        first_msg = await message.channel.send("ğŸ¤– æ”¶åˆ°æåŠï¼Œæ­£åœ¨æ€è€ƒ...")
        thinking_messages.append(first_msg)
        final_response = ""  # å„²å­˜æœ€çµ‚å®Œæ•´å›æ‡‰
        try:
            # éåŒæ­¥è¿­ä»£å™¨å–å¾—é€æ­¥æ›´æ–°çš„å›æ‡‰
            async for partial in stream_response(user_input, message.channel.id):
                final_response = partial  # æ›´æ–°æœ€æ–°ç´¯ç©å›æ‡‰
                # å°‡ç´¯ç©çš„å›æ‡‰åˆ‡å‰²ç‚ºå¤šå€‹ä¸è¶…é2000å­—çš„æ®µè½
                segments = [partial[i:i+2000] for i in range(0, len(partial), 2000)]
                for idx, seg in enumerate(segments):
                    if idx < len(thinking_messages):
                        # ç·¨è¼¯å·²å­˜åœ¨çš„è¨Šæ¯
                        try:
                            await thinking_messages[idx].edit(content=seg)
                        except Exception as e:
                            print(f"[DEBUG] ç·¨è¼¯è¨Šæ¯å¤±æ•—: {e}")
                    else:
                        # ç™¼é€æ–°è¨Šæ¯
                        new_msg = await message.channel.send(seg)
                        thinking_messages.append(new_msg)
                # ç­‰å¾…0.1ç§’å†è™•ç†ä¸‹ä¸€æ¬¡æ›´æ–°
                await asyncio.sleep(0.1)
            # å›æ‡‰å…¨éƒ¨å–å¾—å®Œç•¢å¾Œï¼Œè¨˜éŒ„å›æ‡‰æ­·å²
            memory.save_context({"input": user_input}, {"output": final_response})
            print("[DEBUG] Full response processed:", final_response)
            save_history_to_file(message.channel.id)  # ä¿å­˜é »é“ç‰¹å®šçš„è¨˜æ†¶æ­·å²
        except Exception as e:
            # ç™¼ç”ŸéŒ¯èª¤æ™‚æ›´æ–°æœ€å¾Œä¸€å‰‡è¨Šæ¯
            await thinking_messages[-1].edit(content=f"â—ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    # è™•ç†å…¶ä»–æŒ‡ä»¤
    await bot.process_commands(message)

bot.run(DISCORD_TOKEN)
