import json
import discord
from discord.ext import commands
import requests
from langchain.memory import ConversationBufferMemory
import time
import asyncio
import os
import base64
from PIL import Image
from io import BytesIO

# æ¨¡å‹å°æ‡‰çš„æœ€å¤§ token é™åˆ¶
MODEL_MAX_TOKENS = {
    "gemma2:latest": 8192,
    "phi4:latest": 8192,
    "Qwen2.5:7b": 4096,
    "mistral:latest": 8192,
    "llama3.2:latest": 131072,
    "llama3.2-vision:latest": 131072,
    "deepseek-r1:1.5b": 131072,
    "deepseek-r1:latest": 131072,
    "deepseek-r1:8b": 131072,
    "deepseek-r1:14b": 131072,
    "gemma3:12b": 131072,
    "gemma3:27b": 131072,
    "gemma3:nsfw2": 131072,
    "deepseek-r1:32b": 131072
}

# åˆå§‹åŒ–è¨˜æ†¶åŠŸèƒ½
memory = ConversationBufferMemory(
    max_token_limit=128000)  # é»˜èªç‚º phi4 çš„æœ€å¤§ token é™åˆ¶
# ç´€éŒ„ä¸‹è¼‰çš„æª”æ¡ˆå…§å®¹
file_contents = []
# è¼‰å…¥é…ç½®æ–‡ä»¶
with open("config.json", "r") as config_file:
    config = json.load(config_file)

# Discord Bot Token
DISCORD_TOKEN = config["DISCORD_TOKEN"]
# Ollama API URL
OLLAMA_API_URL = "http://localhost:11434/api/generate"

# æŒ‡å®šä¸Šç·šè¨Šæ¯çš„é »é“ ID
STATUS_CHANNEL_ID = 1073495605286027267  # æ›¿æ›ç‚ºä½ çš„é »é“ ID
ALLOWED_CHANNEL_IDS =[1073495605286027267,
                    1355015638979969097] 

# åˆå§‹åŒ– Bot
intents = discord.Intents.default()
intents.messages = True  # å•Ÿç”¨è¨Šæ¯äº‹ä»¶
intents.message_content = True  # å•Ÿç”¨è¨Šæ¯å…§å®¹è¨ªå•
bot = commands.Bot(command_prefix="++", intents=intents)

# å„²å­˜ç•¶å‰é¸æ“‡çš„æ¨¡å‹
current_model = "gemma3:27b"  # é è¨­æ¨¡å‹


def is_in_allowed_channel(ctx):
    return ctx.channel.id in ALLOWED_CHANNEL_IDS


def update_memory_limit():
    """æ ¹æ“šç•¶å‰æ¨¡å‹æ›´æ–°è¨˜æ†¶æœ€å¤§ token é™åˆ¶"""
    global memory
    max_tokens = MODEL_MAX_TOKENS.get(current_model, 8192)  # é»˜èªç‚º 8192
    memory = ConversationBufferMemory(max_token_limit=max_tokens)
    print(f"[DEBUG] è¨˜æ†¶æœ€å¤§ token é™åˆ¶æ›´æ–°ç‚º: {max_tokens}")


def save_history_to_file():
    """å°‡è¨˜æ†¶æ­·å²ä¿å­˜åˆ° JSON æ–‡ä»¶ä¸­"""
    context = memory.load_memory_variables({})
    with open("history.json", "w", encoding="utf-8") as history_file:
        json.dump(context, history_file, ensure_ascii=False, indent=4)
    print("[DEBUG] è¨˜æ†¶å·²ä¿å­˜åˆ° history.json")


def trim_memory_with_ollama():
    """ä½¿ç”¨ Ollama æ¨¡å‹è£å‰ªè¨˜æ†¶æ­·å²"""
    context = memory.load_memory_variables({})
    history = context.get("history", "")
    estimated_tokens = len(history.split())  # ç°¡å–®ä¼°ç®—tokenæ•¸
    
    # å¦‚æœtokenæ•¸å°æ–¼æœ€å¤§é™åˆ¶çš„50%ï¼Œä¸éœ€è£æ¸›
    if estimated_tokens < MODEL_MAX_TOKENS[current_model] * 0.5:
        print(f"[DEBUG] ç•¶å‰tokenæ•¸ï¼ˆç´„{estimated_tokens}ï¼‰ä¸éœ€è£æ¸›")
        return

    # ç™¼é€è«‹æ±‚åˆ° Ollama æ¨¡å‹
    trim_prompt = """è«‹åˆ†æä»¥ä¸‹å°è©±æ­·å²ï¼Œä¸¦é€²è¡Œé‡è¦å…§å®¹æå–ï¼š
    1. ä¿ç•™é—œéµçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    2. ä¿æŒå°è©±çš„é€£è²«æ€§
    3. å„ªå…ˆä¿ç•™æœ€è¿‘çš„å°è©±
    4. åˆªé™¤é‡è¤‡æˆ–ä¸é‡è¦çš„å…§å®¹
    
    å°è©±æ­·å²ï¼š
    {history}
    
    è«‹æä¾›ç²¾ç°¡å¾Œçš„é‡è¦å°è©±ï¼š""".format(history=history)

    response = requests.post(
        OLLAMA_API_URL,
        json={"model": current_model, "prompt": trim_prompt},
        headers={"Content-Type": "application/json"}
    )

    if response.status_code == 200:
        try:
            result = response.json()
            trimmed_history = result.get("response", "")
            print("[DEBUG] è£å‰ªå¾Œçš„è¨˜æ†¶æ­·å²ï¼š", trimmed_history)
            print(f"[DEBUG] è£å‰ªå‰tokenæ•¸ï¼š{estimated_tokens}ï¼Œè£å‰ªå¾Œtokenæ•¸ï¼š{len(trimmed_history.split())}")

            # æ›´æ–°è¨˜æ†¶
            memory.save_context({"input": ""}, {"output": trimmed_history})
            save_history_to_file()  # ä¿å­˜è£å‰ªå¾Œçš„è¨˜æ†¶
        except json.JSONDecodeError as e:
            print("[ERROR] ç„¡æ³•è§£æè£å‰ªå›æ‡‰ï¼š", e)
    else:
        print("[ERROR] Ollama API è¿”å›éŒ¯èª¤ï¼š", response.status_code, response.text)


def process_user_input(user_input):
    """è™•ç†ç”¨æˆ¶è¼¸å…¥ï¼Œä½¿ç”¨ Ollama API ä¸¦å„²å­˜è¨˜æ†¶"""
    try:
        # æª¢æŸ¥ä¸¦å¯èƒ½è£æ¸›è¨˜æ†¶
        context = memory.load_memory_variables({})
        current_tokens = len(context.get("history", "").split())  # ç°¡å–®ä¼°ç®—tokenæ•¸
        
        # å¦‚æœè¶…éæœ€å¤§é™åˆ¶çš„80%ï¼Œè§¸ç™¼è£æ¸›
        if current_tokens > MODEL_MAX_TOKENS[current_model] * 0.8:
            print(f"[DEBUG] ç•¶å‰tokenæ•¸ï¼ˆç´„{current_tokens}ï¼‰è¶…éé™åˆ¶çš„80%ï¼Œè§¸ç™¼è£æ¸›")
            trim_memory_with_ollama()
            # é‡æ–°è¼‰å…¥è£æ¸›å¾Œçš„ä¸Šä¸‹æ–‡
            context = memory.load_memory_variables({})

        prompt_with_memory = context.get("history", "") + f"\nUser: {user_input}\nBot:"

        print("[DEBUG] Prompt sent to Ollama API:", prompt_with_memory)
        start_time = time.time()
        full_prompt = f"å¦‚æˆ‘ç”¨ç¹é«”ä¸­æ–‡å•å•é¡Œï¼Œä¹Ÿè«‹ä½ ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦ä¸ä½¿ç”¨ä»»ä½•ç‰¹æ®Šå­—ç¬¦å’Œè¡¨æƒ…ï¼š{prompt_with_memory}"
        prompt_with_memory = full_prompt
        # ç™¼é€åˆ° Ollama API
        response = requests.post(
            OLLAMA_API_URL,
            json={"model": current_model, "prompt": prompt_with_memory},
            headers={"Content-Type": "application/json"}
        )

        if response.status_code == 200:
            try:
                # è¨ˆç®—è™•ç†æ™‚é–“
                elapsed_time = time.time() - start_time
                # æª¢æŸ¥æ˜¯å¦ç‚ºé€è¡Œ JSON å›æ‡‰
                if '\n' in response.text:
                    full_response = ""
                    for line in response.text.splitlines():
                        try:
                            data = json.loads(line)
                            full_response += data.get("response", "")
                            if data.get("done", False):
                                break
                        except json.JSONDecodeError:
                            continue
                    memory.save_context({"input": user_input}, {
                                        "output": full_response})
                    print("[DEBUG] Full response processed:", full_response)
                    save_history_to_file()  # ä¿å­˜è¨˜æ†¶æ­·å²
                    return full_response.strip(), elapsed_time
                else:
                    # å–®è¡Œ JSON å›æ‡‰
                    result = response.json()
                    bot_response = result.get("response", "æ¨¡å‹æœªè¿”å›å…§å®¹ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
                    # æ›´æ–°è¨˜æ†¶
                    memory.save_context({"input": user_input}, {
                                        "output": bot_response})
                    print("[DEBUG] Single-line response:", bot_response)
                    save_history_to_file()  # ä¿å­˜è¨˜æ†¶æ­·å²
                    return bot_response, elapsed_time
            except json.JSONDecodeError as e:
                raise Exception(f"JSON è§£ç¢¼éŒ¯èª¤ï¼š{e}")
        else:
            raise Exception(
                f"Ollama API Error: {response.status_code} - {response.text}"
            )
    except Exception as e:
        raise Exception(f"è™•ç†è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

def handle_file_upload(filepath):
    """è™•ç†æ–‡ä»¶ä¸Šå‚³ï¼Œä¸¦è¿”å›æ–‡ä»¶å…§å®¹"""
    global file_contents
    try:
        ext = os.path.splitext(filepath)[1].lower()
        channel_id = os.path.dirname(filepath)  # ç²å–é »é“ ID
        
        # è™•ç†åœ–ç‰‡æª”æ¡ˆ
        if ext in ('.png', '.jpg', '.jpeg', '.gif', '.bmp'):
            try:
                img_content = image_to_base64(filepath)
                if img_content:
                    # ä¿å­˜ base64 åœ–ç‰‡åˆ—è¡¨åˆ°é »é“è³‡æ–™å¤¾
                    base64_file_path = os.path.join(channel_id, 'image_base64_list.json')
                    try:
                        # è®€å–ç¾æœ‰çš„ base64 åˆ—è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if os.path.exists(base64_file_path):
                            with open(base64_file_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                existing_data = data.get('images', [])
                                idle_count = data.get('idle_count', 0)
                        else:
                            existing_data = []
                            idle_count = 0
                        
                        # é‡ç½® idle count å› ç‚ºæœ‰æ–°åœ–ç‰‡
                        idle_count = 0
                        
                        # æ·»åŠ æ–°çš„ base64 åœ–ç‰‡
                        image_data = {
                            'filename': os.path.basename(filepath),
                            'base64_content': img_content,
                            'timestamp': time.time()
                        }
                        existing_data.append(image_data)
                        
                        # ä¿å­˜æ›´æ–°å¾Œçš„åˆ—è¡¨å’Œ idle count
                        with open(base64_file_path, 'w', encoding='utf-8') as f:
                            json.dump({
                                'images': existing_data,
                                'idle_count': idle_count
                            }, f, ensure_ascii=False, indent=4)
                        
                        print(f"[DEBUG] å·²ä¿å­˜ base64 åœ–ç‰‡åˆ°: {base64_file_path}")
                    except Exception as e:
                        print(f"[ERROR] ä¿å­˜ base64 åœ–ç‰‡åˆ—è¡¨æ™‚å‡ºéŒ¯: {e}")
                    
                    return True
            except Exception as e:
                print(f"[ERROR] åœ–ç‰‡è™•ç†éŒ¯èª¤: {e}")
                return False
        
        # è™•ç†æ–‡å­—æª”æ¡ˆ
        else:
            file_content = read_file_content(filepath)
            if file_content != "[Unsupported file type]":
                file_contents.append(f"æª”æ¡ˆåç¨±: {filepath}\næª”æ¡ˆå…§å®¹: {file_content}")
                print(f"[DEBUG] å·²è®€å–æª”æ¡ˆå…§å®¹: {filepath}")
                return True
            else:
                print(f"[WARNING] ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {filepath}")
                return False
                
    except Exception as e:
        print(f"[ERROR] æª”æ¡ˆè™•ç†éŒ¯èª¤: {e}")
        return False

def image_idle_check(channel_id):
    """æª¢æŸ¥ä¸¦ç®¡ç†åœ–ç‰‡å¿«å–
    - æ¯æ¬¡è¢«æåŠæ™‚å¢åŠ é–’ç½®è¨ˆæ•¸
    - ç•¶åœ–ç‰‡è¶…éæœ€å¤§æ•¸é‡æˆ–é–’ç½®æ¬¡æ•¸éå¤šæ™‚æ¸…ç†
    - æ¸…ç†æ™‚å„ªå…ˆæ¸…ç†æœ€èˆŠçš„åœ–ç‰‡
    """
    # è¨­å®šæœ€å¤§åœ–ç‰‡æ•¸é‡å’Œæœ€å¤§é–’ç½®æ¬¡æ•¸
    MAX_IMAGES = 10
    MAX_IDLE_COUNT = 20
    
    try:
        base64_file_path = os.path.join(str(channel_id), 'image_base64_list.json')
        if os.path.exists(base64_file_path):
            with open(base64_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                image_data_list = data.get('images', [])
                idle_count = data.get('idle_count', 0)
            
            # å¢åŠ é–’ç½®è¨ˆæ•¸
            idle_count += 1
            
            # æª¢æŸ¥é–’ç½®æ¬¡æ•¸
            if idle_count > MAX_IDLE_COUNT and image_data_list:
                # ç§»é™¤æœ€èˆŠçš„åœ–ç‰‡
                image_data_list.pop(0)
                print("[DEBUG] å¤ªä¹…æ²’ç”¨ï¼Œå·²ç§»é™¤æœ€èˆŠçš„åœ–ç‰‡")
                print(f"[DEBUG] ç•¶å‰å¿«å–åœ–ç‰‡æ•¸é‡: {len(image_data_list)}, é–’ç½®æ¬¡æ•¸: {idle_count}")
            
            # æª¢æŸ¥åœ–ç‰‡æ•¸é‡æ˜¯å¦è¶…éé™åˆ¶
            while len(image_data_list) > MAX_IMAGES:
                image_data_list.pop(0)  # ç§»é™¤æœ€èˆŠçš„åœ–ç‰‡
                print("[DEBUG] åœ–ç‰‡æ•¸é‡è¶…éé™åˆ¶ï¼Œå·²ç§»é™¤æœ€èˆŠçš„åœ–ç‰‡")
            
            # ä¿å­˜æ›´æ–°å¾Œçš„åˆ—è¡¨å’Œ idle count
            with open(base64_file_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'images': image_data_list,
                    'idle_count': idle_count
                }, f, ensure_ascii=False, indent=4)
            
    except Exception as e:
        print(f"[ERROR] åœ–ç‰‡å¿«å–ç®¡ç†éŒ¯èª¤: {e}")
        # ç™¼ç”ŸéŒ¯èª¤æ™‚é‡ç½®ç‹€æ…‹
        if os.path.exists(base64_file_path):
            with open(base64_file_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'images': [],
                    'idle_count': 0
                }, f)


def image_to_base64(image_path):
    """å°‡åœ–ç‰‡è½‰æ›ç‚º base64 ç·¨ç¢¼"""
    try:
        with Image.open(image_path) as img:
            buffered = BytesIO()
            # ç¢ºå®šåœ–ç‰‡çš„æ ¼å¼
            image_format = img.format.lower() if img.format else 'png'
            
            # æ ¹æ“šåœ–ç‰‡æ ¼å¼é¸æ“‡ä¿å­˜æ ¼å¼
            save_format = {
                'jpeg': 'JPEG',
                'jpg': 'JPEG',
                'gif': 'GIF',
                'bmp': 'BMP',
                'tiff': 'TIFF',
                'png': 'PNG'
            }.get(image_format, 'PNG')
            
            img.save(buffered, format=save_format)
            return base64.b64encode(buffered.getvalue()).decode('utf-8')
    except Exception as e:
        print(f"[ERROR] åœ–ç‰‡è½‰æ›éŒ¯èª¤ {image_path}: {e}")
        return None

def read_file_content(filepath):
    """è®€å–æ–‡ä»¶å…§å®¹"""
    ext = os.path.splitext(filepath)[1].lower()
    
    try:
        if ext == '.txt':
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
                return content if content.strip() else "[Empty file]"
        # åœ¨é€™è£¡å¯ä»¥æ·»åŠ å…¶ä»–æ–‡ä»¶é¡å‹çš„æ”¯æŒ
        # elif ext == '.pdf':
        #     ...
        # elif ext == '.docx':
        #     ...
        else:
            return "[Unsupported file type]"
    except UnicodeDecodeError:
        return "[File encoding error]"
    except Exception as e:
        print(f"[ERROR] æª”æ¡ˆè®€å–éŒ¯èª¤ {filepath}: {e}")
        return f"[Error reading file: {str(e)}]"

@bot.event
async def on_ready():
    """ç•¶ Bot ä¸Šç·šæ™‚è§¸ç™¼"""
    print("Bot å·²æˆåŠŸå•Ÿå‹•ï¼")
    print(f"å·²ç™»å…¥ Discord å¸³æˆ¶ï¼š{bot.user}")

    # # ç™¼é€ä¸Šç·šé€šçŸ¥åˆ°æŒ‡å®šé »é“
    # try:
    #     status_channel = bot.get_channel(STATUS_CHANNEL_ID)
    #     if status_channel:
    #         await status_channel.send("ğŸ¤– Bot å·²ä¸Šç·šï¼Œæº–å‚™æ¥æ”¶æŒ‡ä»¤ï¼")
    #     else:
    #         print(f"ç„¡æ³•æ‰¾åˆ°é »é“ IDï¼š{STATUS_CHANNEL_ID}")
    # except Exception as e:
    #     print(f"ç™¼é€ä¸Šç·šé€šçŸ¥æ™‚å‡ºç¾éŒ¯èª¤ï¼š{e}")
    # ç™¼é€ä¸Šç·šé€šçŸ¥åˆ°æ‰€æœ‰å…è¨±çš„é »é“
    for channel_id in ALLOWED_CHANNEL_IDS:
        channel = bot.get_channel(channel_id)
        if channel:
            try:
                await channel.send("ğŸ¤– Bot å·²ä¸Šç·šï¼Œæº–å‚™æ¥æ”¶æŒ‡ä»¤ï¼")
            except Exception as e:
                print(f"ç™¼é€ä¸Šç·šé€šçŸ¥åˆ°é »é“ {channel_id} æ™‚å‡ºç¾éŒ¯èª¤ï¼š{e}")
        else:
            print(f"ç„¡æ³•æ‰¾åˆ°é »é“ IDï¼š{channel_id}")

bot.remove_command("help")


@bot.command()
@commands.check(is_in_allowed_channel)
async def help(ctx):
    """é¡¯ç¤ºå¯ç”¨æŒ‡ä»¤æ¸…å–®"""
    help_message = """
ğŸ¤– **å¯ç”¨æŒ‡ä»¤æ¸…å–®**:
1. **++chat <è¨Šæ¯>** - èˆ‡ Bot é€²è¡Œå°è©±ã€‚
2. **++setmodel <æ¨¡å‹åç¨±>** - é¸æ“‡è¦ä½¿ç”¨çš„æ¨¡å‹ã€‚
3. **++help** - é¡¯ç¤ºæ­¤å¹«åŠ©è¨Šæ¯ã€‚
4. **++clean_history** - æ¸…é™¤è¨˜æ†¶æ­·å²ã€‚

ğŸ“˜ **å¯ç”¨æ¨¡å‹**:
- é è¨­æ¨¡å‹: gemma3:27b
- gemma3:12b    å¿«é€Ÿå›ç­”ï¼Œä¸€èˆ¬ä½¿ç”¨ï¼Œåœ–ç‰‡ç†è§£å‹‰å¼·
- gemma3:27b    å›ç­”é€Ÿåº¦æ…¢ï¼Œèƒ½åŠ›è¼ƒå¥½ï¼Œåœ–ç‰‡ç†è§£å¼·(è‡ªå¸¶è‹±æ–‡OCR)
- gemma3:nsfw2  NSFWé­”æ”¹ç‰ˆ,æœ‰æ™‚å€™æœƒèƒ¡è¨€äº‚èª
- deepseek-r1:32b é«˜ç­‰è¤‡é›œåº¦ æœƒè¼¸å‡ºæ¨ç†(æ€è€ƒ)éç¨‹
ğŸ¯ **ä½¿ç”¨æ–¹å¼**:
- è¼¸å…¥ `++chat ä½ å¥½` èˆ‡ Bot é–‹å§‹å°è©±ã€‚
- è¼¸å…¥ `++setmodel gemma3:27b` åˆ‡æ›åˆ°æŒ‡å®šçš„æ¨¡å‹ã€‚
- è¼¸å…¥ `++help` æŸ¥çœ‹å¯ç”¨æŒ‡ä»¤æ¸…å–®ã€‚
- è¼¸å…¥ `++clean_history` æ¸…é™¤è¨˜æ†¶æ­·å²ã€‚
"""
    await ctx.send(help_message)


@commands.check(is_in_allowed_channel)
@bot.command(name="chat")
async def chat(ctx, *, user_input: str):
    """è™•ç†èŠå¤©æŒ‡ä»¤"""
    try:
        print(f"æ”¶åˆ°æŒ‡ä»¤ï¼š{user_input}")
        thinking_message = await ctx.send(f"å·²æ”¶åˆ°ï¼š{user_input}ï¼Œæ­£åœ¨æ€è€ƒ...")

        # ç”Ÿæˆ Ollama å›æ‡‰
        response, _ = process_user_input(user_input)
        response = response.strip()
        await thinking_message.delete()

        if response and response != "æ¨¡å‹æœªè¿”å›å…§å®¹ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚":
            await ctx.send(response)
        else:
            await ctx.send("æ¨¡å‹æœªè¿”å›å…§å®¹æˆ–ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
    except Exception as e:
        print("[ERROR] Exception in chat command:", e)
        await ctx.send(f"å‡ºç¾éŒ¯èª¤ï¼š{e}")


@bot.command()
@commands.check(is_in_allowed_channel)
async def setmodel(ctx, model_name: str):
    """è¨­å®šä½¿ç”¨çš„æ¨¡å‹"""
    global current_model
    available_models = ["gemma3:nsfw2", "gemma3:27b","gemma3:12b","deepseek-r1:32b"]
    if model_name in available_models:
        current_model = model_name
        update_memory_limit()  # æ›´æ–°è¨˜æ†¶é™åˆ¶
        print("[DEBUG] Model switched to:", model_name)
        await ctx.send(f"å·²å°‡æ¨¡å‹åˆ‡æ›ç‚º `{model_name}`ï¼Œè¨˜æ†¶æœ€å¤§é™åˆ¶æ›´æ–°ç‚º {MODEL_MAX_TOKENS[model_name]} tokensã€‚")
    else:
        print("[ERROR] Invalid model name:", model_name)
        await ctx.send(f"ç„¡æ•ˆçš„æ¨¡å‹åç¨±ï¼å¯ç”¨æ¨¡å‹ï¼š{', '.join(available_models)}")


@bot.command()
@commands.check(is_in_allowed_channel)
async def clean_history(ctx):
    """æ¸…é™¤è¨˜æ†¶æ­·å²å’Œä¸‹è¼‰çš„æª”æ¡ˆ"""
    global memory,  file_contents
    
    # æ¸…ç©ºåˆ—è¡¨
    file_contents = []
    
    # æ¸…é™¤è¨˜æ†¶æ­·å²
    memory = ConversationBufferMemory(
        max_token_limit=MODEL_MAX_TOKENS.get(current_model, 8192))
    print("[DEBUG] è¨˜æ†¶æ­·å²å·²æ¸…é™¤")
    
    # æ¸…é™¤ userFile ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
    try:
        userfile_dir = str(ctx.channel.id)
        if os.path.exists(userfile_dir):
            for filename in os.listdir(userfile_dir):
                file_path = os.path.join(userfile_dir, filename)
                try:
                    if os.path.isfile(file_path):
                        os.unlink(file_path)
                        print(f"[DEBUG] å·²åˆªé™¤æª”æ¡ˆ: {file_path}")
                except Exception as e:
                    print(f"[ERROR] åˆªé™¤æª”æ¡ˆæ™‚å‡ºéŒ¯ {file_path}: {e}")
            print("[DEBUG] userFile ç›®éŒ„å·²æ¸…ç©º")
    except Exception as e:
        print(f"[ERROR] æ¸…ç† userFile ç›®éŒ„æ™‚å‡ºéŒ¯: {e}")
    
    await ctx.send("è¨˜æ†¶æ­·å²å’Œä¸‹è¼‰çš„æª”æ¡ˆå·²æˆåŠŸæ¸…é™¤ï¼")




async def stream_response(user_input, channel_id):
    """
    ä½¿ç”¨æµå¼è«‹æ±‚å¾ Ollama API å–å¾—éƒ¨åˆ†å›æ‡‰ï¼Œä¸¦æ¯å…©ç§’ yield ç•¶å‰ç´¯ç©å…§å®¹
    """
    # æ•´åˆä¸Šä¸‹æ–‡è¨˜æ†¶
    context = memory.load_memory_variables({})
    current_tokens = len(context.get("history", "").split())  # ç°¡å–®ä¼°ç®—tokenæ•¸
    
    # å¦‚æœè¶…éæœ€å¤§é™åˆ¶çš„80%ï¼Œè§¸ç™¼è£æ¸›
    if current_tokens > MODEL_MAX_TOKENS[current_model] * 0.8:
        print(f"[DEBUG] ç•¶å‰tokenæ•¸ï¼ˆç´„{current_tokens}ï¼‰è¶…éé™åˆ¶çš„80%ï¼Œè§¸ç™¼è£æ¸›")
        trim_memory_with_ollama()
        # é‡æ–°è¼‰å…¥è£æ¸›å¾Œçš„ä¸Šä¸‹æ–‡
        context = memory.load_memory_variables({})

    prompt_with_memory = context.get("history", "") + f"\nUser: {user_input}\nBot:"
    print("[DEBUG] Prompt sent to Ollama API:", prompt_with_memory)
    
    full_prompt = f"å¦‚æˆ‘ç”¨ç¹é«”ä¸­æ–‡å•å•é¡Œï¼Œä¹Ÿè«‹ä½ ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦ä¸ä½¿ç”¨ä»»ä½•ç‰¹æ®Šå­—ç¬¦å’Œè¡¨æƒ…ï¼š{prompt_with_memory}"
    
    # å¾ JSON æª”æ¡ˆè®€å–åœ–ç‰‡åˆ—è¡¨
    base64_images = []
    base64_file_path = os.path.join(str(channel_id), 'image_base64_list.json')
    if os.path.exists(base64_file_path):
        try:
            with open(base64_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                image_data_list = data.get('images', [])
                base64_images = [item['base64_content'] for item in image_data_list]
                print(f"[DEBUG] å·²å¾ {base64_file_path} è®€å– {len(base64_images)} å¼µåœ–ç‰‡")
        except Exception as e:
            print(f"[ERROR] è®€å–åœ–ç‰‡åˆ—è¡¨æ™‚å‡ºéŒ¯: {e}")
    
    # ä½¿ç”¨ requests çš„ stream æ¨¡å¼ (run_in_executor é¿å…é˜»å¡)
    loop = asyncio.get_event_loop()
    response = await loop.run_in_executor(
        None,
        lambda: requests.post(
            OLLAMA_API_URL,
            json={
                "model": current_model,
                "prompt": full_prompt,
                "images": base64_images,
                "stream": True
            },
            headers={"Content-Type": "application/json"},
        )
    )
    
    buffer = ""
    last_update = time.time()
    
    # é€è¡Œè™•ç†æµå¼å›æ‡‰
    for line in response.iter_lines(decode_unicode=True):
        if line:
            try:
                data = json.loads(line)
                new_text = data.get("response", "")
                buffer += new_text
                # æ¯0.5ç§’ yield ç•¶å‰ç´¯ç©çµæœ
                if time.time() - last_update >= 0.5:
                    yield buffer
                    last_update = time.time()
                if data.get("done", False):
                    break
            except json.JSONDecodeError:
                continue
    yield buffer

@bot.event
async def on_message(message):
    global file_contents


    # å¿½ç•¥è‡ªå·±èˆ‡éå…è¨±é »é“è¨Šæ¯
    if message.author == bot.user or message.channel.id not in ALLOWED_CHANNEL_IDS:
        return

    # å‰µå»º userFile ç›®éŒ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(str(message.channel.id), exist_ok=True)
    
    # è™•ç†é™„åŠ æª”æ¡ˆ
    if message.attachments:
        # ç™¼é€åˆå§‹è™•ç†è¨Šæ¯
        processing_msg = await message.channel.send("ğŸ“‚ æ­£åœ¨è™•ç†ä¸Šå‚³çš„æª”æ¡ˆ...")
        
        # ç”¨æ–¼è¨˜éŒ„è™•ç†çµæœçš„åˆ—è¡¨
        processing_results = []
        
        for attachment in message.attachments:
            # è¨­å®šå„²å­˜è·¯å¾‘
            file_path = os.path.join(str(message.channel.id), attachment.filename)
            # ä¸‹è¼‰æª”æ¡ˆ
            await attachment.save(file_path)
            print(f"[DEBUG] å·²ä¸‹è¼‰æª”æ¡ˆ: {file_path}")
            
            # è®€å–æª”æ¡ˆå…§å®¹
            try:
                result = handle_file_upload(file_path)
                if result:
                    ext = os.path.splitext(file_path)[1].lower()
                    if ext in ('.png', '.jpg', '.jpeg', '.gif', '.bmp'):
                        processing_results.append(f"âœ… åœ–ç‰‡ `{attachment.filename}` è™•ç†æˆåŠŸ")
                    else:
                        processing_results.append(f"âœ… æ–‡ä»¶ `{attachment.filename}` è™•ç†æˆåŠŸ")
                else:
                    processing_results.append(f"âŒ æª”æ¡ˆ `{attachment.filename}` è™•ç†å¤±æ•—")
            except Exception as e:
                print(f"[ERROR] è®€å–æª”æ¡ˆéŒ¯èª¤: {e}")
                processing_results.append(f"âŒ æª”æ¡ˆ `{attachment.filename}` è™•ç†å‡ºéŒ¯: {str(e)}")
                file_contents.append(f"æª”æ¡ˆåç¨±: {attachment.filename}\nç„¡æ³•è®€å–æª”æ¡ˆå…§å®¹: {e}")

        # æ›´æ–°è™•ç†è¨Šæ¯ï¼Œé¡¯ç¤ºæ‰€æœ‰æª”æ¡ˆçš„è™•ç†çµæœ
        result_message = "ğŸ“‹ æª”æ¡ˆè™•ç†çµæœï¼š\n" + "\n".join(processing_results)
        await processing_msg.edit(content=result_message)

    # ç•¶è¨Šæ¯æåŠ Bot æ™‚
    if bot.user.mentioned_in(message):
        image_idle_check(message.channel.id)
        user_input = message.content.replace(bot.user.mention, "").strip()
        
        # å¦‚æœæœ‰æª”æ¡ˆï¼Œå°‡æª”æ¡ˆå…§å®¹åŠ å…¥åˆ°ç”¨æˆ¶è¼¸å…¥ä¸­
        if file_contents:
            file_content_text = "\n\n".join(file_contents)
            user_input = f"{user_input}\n\nç”¨æˆ¶ä¸Šå‚³çš„æª”æ¡ˆï¼š\n{file_content_text}"
            print(f"[DEBUG] å·²è®€å–æª”æ¡ˆå…§å®¹+ä½¿ç”¨è€…å•é¡Œ: {user_input}")
        
        if not user_input and not file_contents:
            return
        
        # å…ˆç™¼é€ä¸€å‰‡åˆå§‹è¨Šæ¯ï¼Œä¸¦ç”¨ä¸€å€‹åˆ—è¡¨ä¿å­˜æ‰€æœ‰è¨Šæ¯ï¼ˆå¾ŒçºŒä¾åºæ›´æ–°ï¼‰
        thinking_messages = []
        first_msg = await message.channel.send("ğŸ¤– æ”¶åˆ°æåŠï¼Œæ­£åœ¨æ€è€ƒ...")
        thinking_messages.append(first_msg)
        final_response = ""  # å„²å­˜æœ€çµ‚å®Œæ•´å›æ‡‰
        try:
            # éåŒæ­¥è¿­ä»£å™¨å–å¾—é€æ­¥æ›´æ–°çš„å›æ‡‰
            async for partial in stream_response(user_input, message.channel.id):
                final_response = partial  # æ›´æ–°æœ€æ–°ç´¯ç©å›æ‡‰
                # å°‡ç´¯ç©çš„å›æ‡‰åˆ‡å‰²ç‚ºå¤šå€‹ä¸è¶…é2000å­—çš„æ®µè½
                segments = [partial[i:i+2000] for i in range(0, len(partial), 2000)]
                for idx, seg in enumerate(segments):
                    if idx < len(thinking_messages):
                        # ç·¨è¼¯å·²å­˜åœ¨çš„è¨Šæ¯
                        try:
                            await thinking_messages[idx].edit(content=seg)
                        except Exception as e:
                            print(f"[DEBUG] ç·¨è¼¯è¨Šæ¯å¤±æ•—: {e}")
                    else:
                        # ç™¼é€æ–°è¨Šæ¯
                        new_msg = await message.channel.send(seg)
                        thinking_messages.append(new_msg)
                # ç­‰å¾…0.1ç§’å†è™•ç†ä¸‹ä¸€æ¬¡æ›´æ–°
                await asyncio.sleep(0.1)
            # å›æ‡‰å…¨éƒ¨å–å¾—å®Œç•¢å¾Œï¼Œè¨˜éŒ„å›æ‡‰æ­·å²
            memory.save_context({"input": user_input}, {"output": final_response})
            print("[DEBUG] Full response processed:", final_response)
            save_history_to_file()  # ä¿å­˜è¨˜æ†¶æ­·å²
        except Exception as e:
            # ç™¼ç”ŸéŒ¯èª¤æ™‚æ›´æ–°æœ€å¾Œä¸€å‰‡è¨Šæ¯
            await thinking_messages[-1].edit(content=f"â—ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    # è™•ç†å…¶ä»–æŒ‡ä»¤
    await bot.process_commands(message)

bot.run(DISCORD_TOKEN)
